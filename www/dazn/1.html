<!DOCTYPE html>
<html lang="it">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
    <!-- Link al font Roboto -->
    <style>
        ul {
            margin-left: 30px;
        }

        code {
            font-family: monospace;
            background-color: #f0f0f0;
            padding: 2px 4px;
            border-radius: 4px;
        }
    </style>
</head>

<body>
    <div style="text-align: justify; font-family: 'Roboto', sans-serif;">
        <h2>Background</h2>
        <h4>Breve storia dei protocolli per lo streaming</h4>
        <p>
            I protocolli di streaming multimediale hanno segnato un’importante tappa nell’evoluzione delle tecnologie di
            trasmissione di contenuti su rete Internet,
            consentendo la fruizione di audio e video in tempo reale. Tra i primi protocolli ad essere sviluppati si
            ricorda il
            <a href="https://datatracker.ietf.org/doc/html/rfc2326" target="_blank">Real-Time Streaming Protocol
                (RTSP)</a>, standardizzato nell’RFC 2326 nel 1998,
            progettato per gestire il controllo remoto di flussi multimediali. Nonostante RTSP abbia introdotto
            funzionalità avanzate, come la possibilità di mettere
            in pausa e riprendere lo streaming, esso richiedeva una complessa interazione tra client e server, e
            soffriva di problemi di scalabilità.
        </p>
        <p>
            Parallelamente, il <a href="https://datatracker.ietf.org/doc/html/rfc3550" target="_blank">Real-Time
                Protocol (RTP)</a>, descritto nell'RFC 3550,
            si è affermato come un meccanismo per trasmettere dati multimediali su reti IP. Sebbene RTP fosse efficiente
            nella trasmissione in tempo reale,
            richiedeva l'integrazione con altre tecnologie e non riusciva a garantire da solo una qualità di servizio
            (QoS) adeguata nelle reti pubbliche,
            come Internet, caratterizzate da traffico variabile. In aggiunta, la necessità di modificare parti del
            sistema operativo per implementare questi protocolli
            rendeva la loro adozione complessa e costosa.
        </p>
        <p>
            Un punto di svolta è stato l’affermazione del protocollo HTTP, originariamente concepito per la trasmissione
            di documenti ipertestuali, che ha finito
            per diventare il fondamento anche della distribuzione di contenuti multimediali. L’utilizzo di HTTP ha
            presentato numerosi vantaggi rispetto ai protocolli
            concorrenti, come RTSP e RTP. HTTP, infatti, opera a livello applicativo e non richiede modifiche profonde
            al sistema operativo o alla configurazione
            della rete, rendendolo molto più semplice da implementare su un’ampia varietà di dispositivi. Questo aspetto
            ha consentito di evitare la necessità di
            sviluppare driver o modificare kernel, riducendo significativamente la complessità tecnica.
        </p>
        <p>
            Inoltre, HTTP sfrutta le infrastrutture esistenti di Internet, in particolare i server web e le reti di
            distribuzione dei contenuti (CDN), che erano già
            largamente diffuse per il traffico dati tradizionale. Grazie a questo approccio, i flussi multimediali
            possono essere distribuiti facilmente su larga scala,
            senza richiedere l'implementazione di nuovi protocolli di rete o configurazioni complesse sui server. In tal
            modo, HTTP ha ottenuto una diffusione massiccia,
            sia perché universalmente supportato, sia perché sfrutta porte standard (come la porta 80, o la più
            comune 443, in caso di trasporto attraverso TLS), evitandone il
            blocco da parte di firewall, un problema
            che invece affliggeva protocolli come RTSP.
        </p>
        <p>
            L’aspetto chiave dell’utilizzo di un protocollo a livello applicativo come HTTP risiede nella sua
            flessibilità e adattabilità. Mentre protocolli come
            RTP richiedono specifiche configurazioni di rete e software dedicati, HTTP è compatibile con il normale
            traffico web e supporta nativamente la distribuzione
            di contenuti via CDN. Inoltre, HTTP permette l’adozione di tecniche di caching su vari nodi della rete,
            migliorando ulteriormente la latenza e riducendo
            la congestione. In questo contesto si inserisce il <a href="https://www.iso.org/standard/65274.html"
                target="_blank">MPEG-DASH (Dynamic Adaptive Streaming
                over HTTP)</a>, il protocollo di streaming adottato anche da DAZN, standardizzato nella specifica 
                ISO/IEC 23009-1. DASH sfrutta HTTP per la trasmissione di
            segmenti di contenuto multimediale che vengono
            adattati dinamicamente alla qualità della connessione di rete dell'utente, ottimizzando l’esperienza di
            visione.
        </p>
        <p>
            Grazie a DASH, i contenuti sono suddivisi in piccoli segmenti temporali e distribuiti via HTTP, consentendo
            al client di richiedere i segmenti che meglio
            si adattano alle condizioni di rete, senza interrompere lo streaming. Questo approccio non solo consente una
            maggiore resilienza in ambienti di rete variabili,
            ma offre anche un’esperienza di streaming continua e ad alta definizione. Inoltre, l’integrazione di DASH
            con le CDN esistenti consente una distribuzione
            globale dei contenuti, senza la necessità di sviluppare nuove infrastrutture.
        </p>
        <p>
            <strong>MPEG-DASH</strong> (Dynamic Adaptive Streaming over HTTP) è uno standard di streaming video e audio
            che consente la distribuzione di contenuti multimediali su reti IP attraverso il protocollo HTTP.
            Sviluppato dal <strong>Moving Picture Experts Group (MPEG)</strong>, MPEG-DASH è stato standardizzato come
            ISO/IEC 23009-1 nel 2012. La sua ideazione è stata in risposta alla crescente necessità di ottimizzare la
            fruizione di contenuti multimediali in ambienti di rete variabili, garantendo un'esperienza utente continua
            e di alta qualità.
        </p>
        <h4>MPEG-DASH</h4>
        <p>
            MPEG-DASH è emerso in un contesto in cui il consumo di contenuti video in streaming stava rapidamente
            crescendo, grazie all'aumento della banda larga e all'adozione di dispositivi connessi.
            Precedentemente, i protocolli di streaming erano rigidi e richiedevano configurazioni specifiche della rete
            e dei server, limitando l'efficienza e la scalabilità.
            MPEG-DASH, al contrario, sfrutta l'infrastruttura HTTP esistente, consentendo la distribuzione di contenuti
            attraverso <strong>Content Delivery Networks (CDN)</strong> e facilitando l'adozione di tecniche di caching.
        </p>
        <p>
            Un elemento centrale di MPEG-DASH è il file <strong>MPD</strong> (Media Presentation Description). Questo
            documento di testo, in formato XML, consente di strutturare in modo sistematico la correlazione tra i
            segmenti che componono la traccia audio e/o video e il tempo. Secondo 
        </p>

        <h5>Struttura dell'MPD</h5>
        <p>
            Lo <strong>MPD</strong> (Media Presentation Description) è composto da diverse sezioni, tra cui:
        <ul>
            <li><code>Period</code>: rappresenta un intervallo di tempo nel quale i contenuti possono essere
                visualizzati. Un file MPD può contenere più periodi, ognuno dei quali può avere una propria struttura di
                segmentazione;</li>
            <li><code>AdaptationSet</code>: all'interno di un <code>Period</code>, troviamo uno o più
                <code>AdaptationSet</code>. Ogni <code>AdaptationSet</code> raggruppa insieme diverse rappresentazioni
                (o quality levels) di un contenuto specifico, come video o audio. Di fatto, ogni
                <code>AdaptationSet</code> coincide, secondo la terminologia REST API, a una risorsa. Di ciascuna
                risorsa sono pertanto disponibili diverse rappresentazioni, che, nel contesto applicativo e specifico,
                coincidono con le qualità di codifica disponibili;
            </li>
            <li><code>RepresentationSets</code>: ogni <code>AdaptationSet</code> contiene una o più
                <code>RepresentationSets</code>, ognuna delle quali rappresenta una specifica qualità o un formato del
                contenuto. Le rappresentazioni differiscono per bitrate, risoluzione, codec e altri parametri.
            </li>
        </ul>
        </p>

        <h5><code>AdaptationSet</code></h5>
        <p>
            La struttura di un <code>AdaptationSet</code> include attributi chiave, come:
        <ul>
            <li><code>mimeType</code>: specifica la tipologia della risorsa; generalmente coincidente con
                <code>video/mp4</code> o <code>audio/mp4</code>. Audio e video sono disponibili con estensione
                <code>.mp4</code> (molto comune), oppure <code>.cmfv</code> (per il video) e <code>.cmfa</code> (per
                l'audio);
            </li>
            <li><code>segmentAlignment</code>: indica se i segmenti sono allineati. Se il valore è <code>true</code>, i
                segmenti nelle diverse rappresentazioni (ad es. 720p o 1080p) iniziano e finiscono nello stesso punto
                temporale. Questo consente al client di passare da una rappresentazione all'altra senza interruzioni
                durante la riproduzione. L'allineamento dei segmenti è fondamentale per garantire un'esperienza di
                streaming fluida, soprattutto in condizioni di rete variabili;</li>
            <li><code>minimumUpdatePeriod</code>: definisce il periodo minimo per gli aggiornamenti del file MPD. Questo
                campo indica al client ogni quanto tempo deve controllare per eventuali aggiornamenti del manifesto MPD.
                È particolarmente utile per i flussi live o per contenuti che possono essere aggiornati dinamicamente,
                come nuovi segmenti video che vengono creati e pubblicati durante lo streaming di un evento dal vivo.
            </li>
        </ul>
        </p>

        <h5><code>RepresentationSet</code></h5>
        <p>
            Ogni <code>RepresentationSet</code> all'interno di un <code>AdaptationSet</code> ha attributi specifici
            come:
        <ul>
            <li><code>id</code>: un identificatore univoco per la rappresentazione, ad esempio "video-720p" per una
                rappresentazione video a 720p.</li>
            <li><code>bandwidth</code>: specifica il bitrate della rappresentazione in bit al secondo. Un bitrate più
                alto, ad esempio "4500000" per video in 1080p, indica una qualità migliore ma richiede una connessione
                di rete più stabile.</li>
            <li><code>width</code> e <code>height</code>: indicano la risoluzione della rappresentazione. Per esempio,
                una risoluzione di 1280x720 (720p) o 1920x1080 (1080p).</li>
            <li><code>codecs</code>: specifica il codec utilizzato per la compressione del contenuto. Per esempio,
                "avc1.64001F" per video H.264 e "mp4a.40.2" per audio AAC.</li>
        </ul>
        </p>
    </div>
</body>

</html>